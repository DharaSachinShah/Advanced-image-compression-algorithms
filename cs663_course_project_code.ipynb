{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab5661b7",
   "metadata": {},
   "source": [
    "Research paper implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324fe9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from scipy.ndimage import laplace\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def detect_edges(image, sigma=1.0, low_thresh=50, high_thresh=150):\n",
    "    \"\"\"Step 1: Detect edges using Marr-Hildreth operator.\"\"\"\n",
    "    blurred = cv2.GaussianBlur(image, (5, 5), sigma)\n",
    "    laplacian = cv2.Laplacian(blurred, cv2.CV_64F)\n",
    "    edges = cv2.Canny(np.uint8(laplacian), low_thresh, high_thresh)\n",
    "    return edges\n",
    "\n",
    "def quantize_and_subsample(image, edges, quantization_levels=16, subsample_step=5):\n",
    "    \"\"\"Step 2: Quantize and subsample pixel values near edges.\"\"\"\n",
    "    quantized = np.round(image / 255 * (quantization_levels - 1)) * (255 / (quantization_levels - 1))\n",
    "    subsampled = np.zeros_like(image)\n",
    "    edge_coords = np.argwhere(edges > 0)\n",
    "    for i, (x, y) in enumerate(edge_coords):\n",
    "        if i % subsample_step == 0:\n",
    "            subsampled[x, y] = quantized[x, y]\n",
    "    return subsampled\n",
    "\n",
    "def homogeneous_diffusion(encoded_image, edges, iterations=100, alpha=0.1):\n",
    "    \"\"\"Step 3: Reconstruct missing values using homogeneous diffusion.\"\"\"\n",
    "    reconstructed = np.copy(encoded_image)\n",
    "    edge_mask = edges > 0  # Fixed pixels are edges\n",
    "    for _ in range(iterations):\n",
    "        laplacian_update = laplace(reconstructed)\n",
    "        reconstructed = reconstructed + alpha * laplacian_update\n",
    "        reconstructed[edge_mask] = encoded_image[edge_mask]  # Keep edge values fixed\n",
    "    return reconstructed\n",
    "\n",
    "def calculate_psnr(original, reconstructed):\n",
    "    \"\"\"Calculate PSNR to compare image quality.\"\"\"\n",
    "    mse = np.mean((original - reconstructed) ** 2)\n",
    "    if mse == 0:\n",
    "        return float('inf')\n",
    "    psnr = 10 * np.log10(255**2 / mse)\n",
    "    return psnr\n",
    "\n",
    "def process_images_from_folder(folder_path, output_folder, sigma=1.0, low_thresh=50, high_thresh=150, quantization_levels=16, subsample_step=5, iterations=100, alpha=0.1):\n",
    "    \"\"\"Process all images in the dataset folder.\"\"\"\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "    # Use the image fetching method as described\n",
    "    image_files = [os.path.join(dp, f) for dp, dn, fn in os.walk(os.path.expanduser(folder_path)) for f in fn if f.endswith(('.jpg', '.png', '.jpeg', '.bmp', '.tif', '.tiff'))]\n",
    "\n",
    "    for image_path in image_files:\n",
    "        # Load image\n",
    "        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        # Step 1: Detect edges\n",
    "        edges = detect_edges(image, sigma, low_thresh, high_thresh)\n",
    "        \n",
    "        # Step 2: Quantize and subsample\n",
    "        quantized_subsampled = quantize_and_subsample(image, edges, quantization_levels, subsample_step)\n",
    "        \n",
    "        # Step 3: Reconstruct using diffusion\n",
    "        reconstructed_image = homogeneous_diffusion(quantized_subsampled, edges, iterations, alpha)\n",
    "        \n",
    "        # Calculate PSNR\n",
    "        psnr_value = calculate_psnr(image, reconstructed_image)\n",
    "#         print(f\"Processed {image_path}: PSNR = {psnr_value:.2f} dB\")\n",
    "        \n",
    "        # Save results\n",
    "        cv2.imwrite(os.path.join(output_folder, f\"{os.path.splitext(os.path.basename(image_path))[0]}_edges.png\"), edges)\n",
    "        cv2.imwrite(os.path.join(output_folder, f\"{os.path.splitext(os.path.basename(image_path))[0]}_reconstructed.png\"), reconstructed_image)\n",
    "        \n",
    "        # Plot and save comparison\n",
    "        plt.figure(figsize=(15, 5))\n",
    "        plt.subplot(1, 3, 1), plt.title('Original'), plt.imshow(image, cmap='gray')\n",
    "        plt.subplot(1, 3, 2), plt.title('Edges'), plt.imshow(edges, cmap='gray')\n",
    "        plt.subplot(1, 3, 3), plt.title('Reconstructed'), plt.imshow(reconstructed_image, cmap='gray')\n",
    "        plt.savefig(os.path.join(output_folder, f\"{os.path.splitext(os.path.basename(image_path))[0]}_comparison.png\"))\n",
    "        plt.close()\n",
    "\n",
    "# Paths\n",
    "dataset_folder = r\"OneDrive - Indian Institute of Technology Bombay/Documents/Data_science_intern/CS663/Weizmann_Seg_DB_1obj/1obj\"  # Your dataset folder\n",
    "output_folder = r\"OneDrive - Indian Institute of Technology Bombay/Documents/Data_science_intern/CS663/Output\"  # Replace with your desired output folder\n",
    "\n",
    "# Process all images in the dataset folder\n",
    "process_images_from_folder(dataset_folder, output_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10e9a28",
   "metadata": {},
   "source": [
    "Research paper implementation & pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64115c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "\n",
    "# PCA-based Image Compression\n",
    "def pca_image_compression(image, n_components=50):\n",
    "    \"\"\"Compress an image using PCA (Principal Component Analysis).\"\"\"\n",
    "    height, width = image.shape\n",
    "    n_components = min(n_components, min(height, width))  # Limit components to the smaller dimension\n",
    "\n",
    "    # Perform PCA on the image along the width (columns)\n",
    "    pca = PCA(n_components=n_components)\n",
    "    transformed = pca.fit_transform(image)  # Transform the image using PCA\n",
    "    reconstructed = pca.inverse_transform(transformed)  # Reconstruct the image\n",
    "\n",
    "    return reconstructed\n",
    "\n",
    "# Edge-based Compression Placeholder Functions\n",
    "def extract_edges(image, sigma=1.0, low_thresh=50, high_thresh=150):\n",
    "    \"\"\"Extract edges using Canny edge detection.\"\"\"\n",
    "    blurred = cv2.GaussianBlur(image, (5, 5), sigma)\n",
    "    edges = cv2.Canny(blurred, low_thresh, high_thresh)\n",
    "    return edges\n",
    "\n",
    "def reconstruct_image(original_image, edges):\n",
    "    \"\"\"Reconstruct the image using edges.\"\"\"\n",
    "    reconstructed = cv2.bitwise_and(original_image, original_image, mask=edges)\n",
    "    return reconstructed\n",
    "\n",
    "# PSNR Calculation\n",
    "def calculate_psnr(original, reconstructed):\n",
    "    \"\"\"Calculate PSNR to compare image quality.\"\"\"\n",
    "    mse = np.mean((original - reconstructed) ** 2)\n",
    "    if mse == 0:\n",
    "        return float('inf')\n",
    "    psnr = 10 * np.log10(255**2 / mse)\n",
    "    return psnr\n",
    "\n",
    "# Compare Edge-based and PCA-based Compression\n",
    "def compare_compression_methods(image, n_components=50, sigma=1.0, low_thresh=50, high_thresh=150):\n",
    "    \"\"\"Compare edge-based compression with PCA-based compression.\"\"\"\n",
    "    # Edge-based Compression\n",
    "    edges = extract_edges(image, sigma, low_thresh, high_thresh)\n",
    "    reconstructed_edge_image = reconstruct_image(image, edges)\n",
    "    psnr_edge = calculate_psnr(image, reconstructed_edge_image)\n",
    "    \n",
    "    # PCA-based Compression\n",
    "    reconstructed_pca_image = pca_image_compression(image, n_components)\n",
    "    psnr_pca = calculate_psnr(image, reconstructed_pca_image)\n",
    "    \n",
    "    print(f\"Edge-based Compression PSNR: {psnr_edge:.2f} dB\")\n",
    "    print(f\"PCA-based Compression PSNR: {psnr_pca:.2f} dB\")\n",
    "    \n",
    "    # Plot and save comparison\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    plt.subplot(1, 3, 1), plt.title('Original'), plt.imshow(image, cmap='gray')\n",
    "    plt.subplot(1, 3, 2), plt.title('Edge-based Reconstructed'), plt.imshow(reconstructed_edge_image, cmap='gray')\n",
    "    plt.subplot(1, 3, 3), plt.title('PCA-based Reconstructed'), plt.imshow(reconstructed_pca_image, cmap='gray')\n",
    "    plt.show()\n",
    "\n",
    "# Process Images in Dataset with PCA Comparison\n",
    "def process_images_and_compare(folder_path, output_folder, n_components=50, sigma=1.0, low_thresh=50, high_thresh=150):\n",
    "    \"\"\"Process all images in the dataset folder and compare both compression methods.\"\"\"\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Fetch all image files in the folder\n",
    "    image_files = [os.path.join(dp, f) for dp, dn, fn in os.walk(os.path.expanduser(folder_path)) for f in fn if f.endswith(('.jpg', '.png', '.jpeg', '.bmp', '.tif', '.tiff'))]\n",
    "\n",
    "    for image_path in image_files:\n",
    "        # Load image\n",
    "        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        if image is None:\n",
    "            print(f\"Error loading image: {image_path}\")\n",
    "            continue\n",
    "\n",
    "        # Save original image\n",
    "        base_filename = os.path.splitext(os.path.basename(image_path))[0]\n",
    "        cv2.imwrite(os.path.join(output_folder, f\"{base_filename}_original.png\"), image)\n",
    "\n",
    "        # Compare the two compression methods\n",
    "        compare_compression_methods(image, n_components, sigma, low_thresh, high_thresh)\n",
    "        \n",
    "        # Optionally save the images for the two methods as well\n",
    "\n",
    "        # Edge-based Reconstructed Image\n",
    "        edges = extract_edges(image, sigma, low_thresh, high_thresh)\n",
    "        reconstructed_edge_image = reconstruct_image(image, edges)\n",
    "        cv2.imwrite(os.path.join(output_folder, f\"{base_filename}_edge_reconstructed.png\"), reconstructed_edge_image)\n",
    "\n",
    "        # PCA-based Reconstructed Image\n",
    "        reconstructed_pca_image = pca_image_compression(image, n_components)\n",
    "        cv2.imwrite(os.path.join(output_folder, f\"{base_filename}_pca_reconstructed.png\"), reconstructed_pca_image)\n",
    "\n",
    "# Paths\n",
    "dataset_folder = r\"OneDrive - Indian Institute of Technology Bombay/Documents/Data_science_intern/CS663/Weizmann_Seg_DB_1obj/1obj\"  # Dataset folder path\n",
    "output_folder = r\"OneDrive - Indian Institute of Technology Bombay/Documents/Data_science_intern/CS663/Output_withPCA\"  # Output folder path\n",
    "\n",
    "# Process all images in the dataset folder and compare methods\n",
    "# process_images_and_compare(dataset_folder, output_folder, n_components=50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0798a8ca",
   "metadata": {},
   "source": [
    "JPEG compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9dcf42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Quantization Matrix\n",
    "DEFAULT_Q_MATRIX = np.array([\n",
    "    [16, 11, 10, 16, 24, 40, 51, 61],\n",
    "    [12, 12, 14, 19, 26, 58, 60, 55],\n",
    "    [14, 13, 16, 24, 40, 57, 69, 56],\n",
    "    [14, 17, 22, 29, 51, 87, 80, 62],\n",
    "    [18, 22, 37, 56, 68, 109, 103, 77],\n",
    "    [24, 35, 55, 64, 81, 104, 113, 92],\n",
    "    [49, 64, 78, 87, 103, 121, 120, 101],\n",
    "    [72, 92, 95, 98, 112, 100, 103, 99],\n",
    "])\n",
    "\n",
    "# Compute 2D DCT\n",
    "def compute_dct(block):\n",
    "    return cv2.dct(block.astype(np.float32))\n",
    "\n",
    "# Compute 2D IDCT\n",
    "def compute_idct(block):\n",
    "    return cv2.idct(block.astype(np.float32))\n",
    "\n",
    "# Quantization\n",
    "def quantize(block, q_matrix):\n",
    "    return np.round(block / q_matrix)\n",
    "\n",
    "# Dequantization\n",
    "def dequantize(block, q_matrix):\n",
    "    return block * q_matrix\n",
    "\n",
    "# JPEG Compression\n",
    "def jpeg_compress(image, q_matrix):\n",
    "    block_size = 8\n",
    "    height, width = image.shape\n",
    "    \n",
    "    # Pad image to make dimensions divisible by block size\n",
    "    padded_height = (height + block_size - 1) // block_size * block_size\n",
    "    padded_width = (width + block_size - 1) // block_size * block_size\n",
    "    padded_image = np.zeros((padded_height, padded_width), dtype=image.dtype)\n",
    "    padded_image[:height, :width] = image\n",
    "\n",
    "    compressed_image = np.zeros_like(padded_image, dtype=np.float32)\n",
    "\n",
    "    # Process each block\n",
    "    for i in range(0, padded_height, block_size):\n",
    "        for j in range(0, padded_width, block_size):\n",
    "            block = padded_image[i:i+block_size, j:j+block_size]\n",
    "            dct_block = compute_dct(block)\n",
    "            quantized_block = quantize(dct_block, q_matrix)\n",
    "            compressed_image[i:i+block_size, j:j+block_size] = quantized_block\n",
    "\n",
    "    return compressed_image[:height, :width]\n",
    "\n",
    "# JPEG Decompression\n",
    "def jpeg_decompress(compressed_image, q_matrix):\n",
    "    block_size = 8\n",
    "    height, width = compressed_image.shape\n",
    "\n",
    "    # Pad compressed image to make dimensions divisible by block size\n",
    "    padded_height = (height + block_size - 1) // block_size * block_size\n",
    "    padded_width = (width + block_size - 1) // block_size * block_size\n",
    "    padded_compressed_image = np.zeros((padded_height, padded_width), dtype=compressed_image.dtype)\n",
    "    padded_compressed_image[:height, :width] = compressed_image\n",
    "\n",
    "    decompressed_image = np.zeros_like(padded_compressed_image, dtype=np.float32)\n",
    "\n",
    "    # Process each block\n",
    "    for i in range(0, padded_height, block_size):\n",
    "        for j in range(0, padded_width, block_size):\n",
    "            block = padded_compressed_image[i:i+block_size, j:j+block_size]\n",
    "            dequantized_block = dequantize(block, q_matrix)\n",
    "            idct_block = compute_idct(dequantized_block)\n",
    "            decompressed_image[i:i+block_size, j:j+block_size] = idct_block\n",
    "\n",
    "    return decompressed_image[:height, :width]\n",
    "\n",
    "# Calculate RMSE\n",
    "def calculate_rmse(original, decompressed):\n",
    "    return np.sqrt(np.mean((original - decompressed) ** 2))\n",
    "\n",
    "# Calculate BPP\n",
    "def calculate_bpp(compressed_image, original_shape):\n",
    "    compressed_bits = np.count_nonzero(compressed_image) * 8  # Assuming each non-zero coefficient is stored as a byte\n",
    "    num_pixels = original_shape[0] * original_shape[1]\n",
    "    return compressed_bits / num_pixels\n",
    "\n",
    "# Process Images from Dataset (RMSE-BPP curve for each image)\n",
    "def process_images_separately(dataset_folder, output_folder, q_matrix, quality_factors):\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Fetch all image files in the folder\n",
    "    image_files = [os.path.join(dp, f) for dp, dn, fn in os.walk(dataset_folder) for f in fn if f.endswith(('.jpg', '.png', '.jpeg', '.bmp', '.tif', '.tiff'))]\n",
    "\n",
    "    for image_path in image_files:\n",
    "        # Load image\n",
    "        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        if image is None:\n",
    "            print(f\"Error loading image: {image_path}\")\n",
    "            continue\n",
    "\n",
    "        rmse_values = []\n",
    "        bpp_values = []\n",
    "\n",
    "        for quality in quality_factors:\n",
    "            scaled_q_matrix = q_matrix * (100 / quality)\n",
    "\n",
    "            # Compress and decompress\n",
    "            compressed = jpeg_compress(image, scaled_q_matrix)\n",
    "            decompressed = jpeg_decompress(compressed, scaled_q_matrix)\n",
    "\n",
    "            # Calculate RMSE and BPP\n",
    "            rmse = calculate_rmse(image, decompressed)\n",
    "            bpp = calculate_bpp(compressed, image.shape)\n",
    "            rmse_values.append(rmse)\n",
    "            bpp_values.append(bpp)\n",
    "\n",
    "        # Plot RMSE vs. BPP for the current image\n",
    "        plt.plot(bpp_values, rmse_values, marker='o')\n",
    "        plt.xlabel('Bits Per Pixel (BPP)')\n",
    "        plt.ylabel('Root Mean Squared Error (RMSE)')\n",
    "        plt.title(f'RMSE vs. BPP for {os.path.basename(image_path)}')\n",
    "        plt.grid()\n",
    "\n",
    "        # Save the plot\n",
    "        base_filename = os.path.splitext(os.path.basename(image_path))[0]\n",
    "        plt.savefig(os.path.join(output_folder, f\"{base_filename}_rmse_bpp_curve.png\"))\n",
    "        plt.clf()  # Clear figure for next image\n",
    "\n",
    "# Main Execution\n",
    "if __name__ == \"__main__\":\n",
    "    dataset_folder = r\"OneDrive - Indian Institute of Technology Bombay/Documents/Data_science_intern/CS663/Weizmann_Seg_DB_1obj/1obj\"\n",
    "    output_folder = r\"OneDrive - Indian Institute of Technology Bombay/Documents/Data_science_intern/CS663/Output_withJPEG\"\n",
    "    \n",
    "    quality_factors = [10, 20, 30, 40, 50]  # Quality factors to evaluate\n",
    "    process_images_separately(dataset_folder, output_folder, DEFAULT_Q_MATRIX, quality_factors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12bc9ebe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5160c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
